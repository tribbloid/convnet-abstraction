{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Tuple\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "if '' in sys.path:\n",
    "    sys.path.remove('')\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../python'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# print(sys.path)\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from graphPlot import drawGraph, SIZE\n",
    "from const import *\n",
    "\n",
    "plt.rcParams['figure.figsize'] = SIZE\n",
    "# print(plt.rcParams['figure.figsize'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# **Tensor Field Network** (and other ConvNet Generalisations)\n",
    "\n",
    "## *TDLS - Feb 11. 2019*\n",
    "\n",
    "### **Chris Dryden**\n",
    "\n",
    "- christopher.paul.dryden@gmail.com\n",
    "\n",
    "- github.com/chrisdryden\n",
    "\n",
    "### **Peng Cheng**\n",
    "\n",
    "- pc175@uowmail.edu.au\n",
    "\n",
    "- datapassports.com\n",
    "\n",
    "- github.com/tribbloid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Overview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g = nx.DiGraph(directed=True)\n",
    "\n",
    "schNet = \"schNet\\n(Nature\\nCommunication\\n2016)\"\n",
    "groupInv = \"Group Equivariant ConvNet\\n(ICML 2016)\"\n",
    "steerable = \"Steerable CNNs\\n(ICLR 2017)\"\n",
    "harmonic = \"Harmonic Net\\n(CVPR 2017)\"\n",
    "spherical = \"Spherical CNNs\\n(ICLR 2018 best paper)\"\n",
    "tensorField = \"*Tensor Field Net*\\n(not peer-reviewed!)\"\n",
    "cgNet = \"Clebsch-Gordan Net\\n(NIPS 2018)\"\n",
    "threeDSteerable = \"3D Steerable CNNs\\n(NIPS 2018)\"\n",
    "\n",
    "g.add_edge(schNet, tensorField)\n",
    "g.add_edge(groupInv, steerable)\n",
    "g.add_edge(harmonic, spherical)\n",
    "g.add_edge(steerable, spherical)\n",
    "g.add_edge(spherical, tensorField)\n",
    "g.add_edge(tensorField, cgNet)\n",
    "g.add_edge(tensorField, threeDSteerable)\n",
    "\n",
    "drawGraph(g)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-ConvNet (1960-1987)\n",
    "\n",
    "<img src=\"assets/winterIsComing.jpg\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-ConvNet - Linear/Fully Connected/~~Dense/Perceptron~~ Layer\n",
    "\n",
    "In pursuing of unbounded representation/approximation power\n",
    "\n",
    "\\begin{align}\n",
    "& \\text{($w$ are weight of neurons)} & f_+(y) = \\Phi \\Big( f(x) \\Big) &= \\phi \\Big( \\sum_{x \\in \\text{domain}} f(x) w(x, y) \\Big) \\\\\n",
    "& \\text{(pardon the abusing of notation)} & &= \\phi \\Big( \\bbox[yellow]{< f(x), w(x, y) >_x} \\Big)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "g = nx.DiGraph(directed=True)\n",
    "\n",
    "g.add_edge(\"$f(x)$\", \"== layer ==\")\n",
    "g.add_edge(\"== layer ==\", \"$f_+(y)$\")\n",
    "g.add_edge(\"$f_+(y)$\", \" == layer ==\")\n",
    "g.add_edge(\" == layer ==\", \"$f_{++}(.)$\")\n",
    "g.add_edge(\"$f_{++}(.)$\", \"...\")\n",
    "\n",
    "dot = \"$f(.)$\\ninput signal\"\n",
    "fc = \"$<f(x), w(x, y)> d x$\\nlinear\"\n",
    "nl = \"$\\phi(<f(x), w(x, y)> d x)$\\nactivation\"\n",
    "dot2 = \"$f_+(y)$\\nhigh-level features\"\n",
    "# hw = \"highway?\"\n",
    "\n",
    "g.add_edge(dot, fc)\n",
    "g.add_edge(fc, nl)\n",
    "g.add_edge(nl, dot2)\n",
    "\n",
    "g2 = g.copy()\n",
    "\n",
    "g2.add_edge(dot, \"$f(x)$\", wedge=True)\n",
    "g2.add_edge(dot2, \"$f_+(y)$\", wedge=True)\n",
    "\n",
    "drawGraph(g2, g, font_family='humor sans')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-ConvNet - Linear Layer\n",
    "\n",
    "<img src=\"assets/kardashian-counterexample.png\">\n",
    "\n",
    "---\n",
    " \n",
    "[*] Image courtesey https://www.quora.com/What-is-the-difference-between-equivariance-and-invariance-in-Convolution-neural-networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invariant Layer / Bag-of-words?\n",
    "\n",
    "- Don't do this\n",
    "\n",
    "<img src=\"assets/picassoEffect.jpg\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "- Good catch\n",
    "\n",
    "<img src=\"assets/data-aug.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "- Too slow in practice\n",
    "    - In **convex case** SGD \"theoretically probably\" converges equally fast\n",
    "    - otherwise it \"kind of works\" but with much less efficiency\n",
    "\n",
    "--- \n",
    "\n",
    "2D translation\n",
    "\n",
    "<img src=\"assets/image-pan.gif\" width=\"600px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "- Time & space complexity increase exponentially with the dimensionality of augmentation\n",
    "\n",
    "---\n",
    "\n",
    "2D translation x 1D rotation, you'll see this fairly often on some cameras\n",
    "\n",
    "<img src=\"assets/human-0g.jpg\"> | <img src=\"assets/drone-overhead.png\">\n",
    "--- | ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "- Time & space complexity increase exponentially with the dimensionality of augmentation\n",
    "\n",
    "---\n",
    "\n",
    "3D rotation\n",
    "\n",
    "<img src=\"assets/fisheye-pan.gif\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "- Time & space complexity increase exponentially with the dimensionality of augmentation\n",
    "\n",
    "---\n",
    "\n",
    "4D affine transformations\n",
    "\n",
    "<img src=\"assets/airr.png\">\n",
    "\n",
    "---\n",
    "\n",
    "[*] Image Courtesy: AIRR https://thedroneracingleague.com/airr/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "- Time & space complexity increase exponentially with the dimensionality of augmentation\n",
    "\n",
    "---\n",
    "\n",
    "3D translation x 3D rotation\n",
    "\n",
    "<img src=\"assets/point-cloud-6d.gif\" width=\"800px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "- Time & space complexity increase exponentially with the dimensionality of augmentation\n",
    "\n",
    "---\n",
    "\n",
    "Air pressure depending on translation\n",
    "\n",
    "<img src=\"assets/IAS-vs-TAS.jpg\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "How about a better idea?\n",
    "\n",
    "- Instead of augmenting, we hard-bake such prior knowledge into the network to yield identical result!\n",
    "\n",
    "<img src=\"assets/aerial-g-conv.jpg\" width=\"500\">\n",
    "\n",
    "---\n",
    "\n",
    "Augmentation types | Answer\n",
    " --- | --- \n",
    "2d translation | ConvNet\n",
    "**others** | **G-ConvNet**\n",
    "- 2d translation + 90$^{\\circ}$ rotation | Group Equivariant CNNs\n",
    "- 2d translation + rotation | Harmonic Net\n",
    "- 3d rotation | Spherical CNNs\n",
    "- 3d translation + rotation | Tensor Field Net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.2",
    "jupytext_version": "0.8.6"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
